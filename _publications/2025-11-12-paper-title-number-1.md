---
title: "Bird’s Eye View Perception for Autonomous Driving: A Comprehensive Survey"
collection: publications
category: manuscripts
permalink: /publication/2025-bev-survey
excerpt: >
  A comprehensive survey covering the evolution, methodologies, datasets, applications,
  and future directions of Bird’s Eye View (BEV) perception for autonomous driving.
date: 2025-01-15
venue: "To be Submitted"
#paperurl: "/files/BEV_Survey.pdf"
citation: >
  To be Declared.
---

### Overview  
This survey provides a comprehensive examination of **Bird’s Eye View (BEV) perception**, a key paradigm in modern autonomous driving systems. We systematically review the evolution from early geometric projection approaches to transformer-based and multi-modal BEV frameworks.

### Key Contributions  
- Presents a unified taxonomy covering **geometry-based**, **depth-based**, **query-based**, **lidar-centric**, and **multi-modal fusion** BEV methods.  
- Summarizes major BEV datasets from 2019–2025, including KITTI-360, nuScenes, Waymo, ONCE, and more.  
- Provides detailed comparisons across modalities (camera / LiDAR / multi-modal), tasks (detection, mapping, segmentation), and benchmarks (NDS, mAP, mIoU).  
- Highlights emerging directions such as **3D Gaussian Splatting BEV**, **foundation perception models**, **world models**, **autonomous driving agents**, and **BEV-Language models**.

### Scope  
This survey aims to serve as a reference for researchers and engineers working on 3D perception, BEV modeling, autonomous driving, multi-modal fusion, and robust perception systems.

